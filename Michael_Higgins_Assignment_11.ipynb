{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [20 pts] In this assignment, we will approach the problem with sentiment analysis in our pipeline to classify movie reviews.\n",
    "Use the Opinion Lexicon from the source: http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
    "Download the two files, positive-words.txt and negative-words.txt and use them to opinion-score each pooled review (i.e., ignore the original class labels). One approach can be counting the number of occurrences of the lexicon words and scoring appropriately.\n",
    "(Hint: Quantize the positive and negative frequencies to 0 and 1,\n",
    "i.e., predict = (opinion_score[:,0] > opinion_score[:,1]) + 0\n",
    ")\n",
    "What is the prediction accuracy when done like in the above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "import re\n",
    "import nltk\n",
    "# Import necessary libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def read_file(file_path):\n",
    "    start_line = 32\n",
    "    words=[]\n",
    "\n",
    "    with open(file_path, 'r', encoding=\"latin-1\") as file:\n",
    "        reader = csv.reader(file, delimiter=',', quotechar='\"')\n",
    "        next(reader)\n",
    "        for line_number, line in enumerate(reader, start=1):\n",
    "            if line_number >= start_line:\n",
    "                words.append(line[0])\n",
    "    return words\n",
    "pos_words=read_file('./positive-words.txt')\n",
    "neg_words=read_file('./negative-words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [[1974, teenager, Martha, Moxley, Maggie, Grac...\n",
       "1        [[really, like, Kris, Kristofferson, usual, ea...\n",
       "2        [[SPOILER, read, think, watching, movie, altho...\n",
       "3        [[people, seen, wonderful, movie, sure, thet, ...\n",
       "4        [[recently, bought, DVD, forgetting, much, hat...\n",
       "                               ...                        \n",
       "49995    [[lets, start, best, building, although, hard,...\n",
       "49996    [[British, heritage, film, industry, control, ...\n",
       "49997    [[dont, even, know, begin, one, family, worst,...\n",
       "49998    [[Richard, Tyler, little, boy, scared, everyth...\n",
       "49999    [[waited, long, watch, movie, Also, like, Bruc...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "def ie_preprocess(document):\n",
    "    # Sentence Parse\n",
    "    document = re.sub('<br />', '', document)\n",
    "    document = re.sub(r'[^\\w\\s]', '', document)\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    \n",
    "    # Word Parse and remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [[word for word in sent if word.lower() not in stop_words and len(word) > 2] for sent in sentences]\n",
    "    \n",
    "    return sentences\n",
    "path = './movie_data.csv'\n",
    "\n",
    "df = pd.read_csv(path, encoding=\"utf-8\")\n",
    "df['review'].apply(ie_preprocess)\n",
    "df.to_csv('preprocessed_movie_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.90302\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a CountVectorizer for text data\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Prepare your features and labels\n",
    "X = tfidf_vectorizer.fit_transform(df['review'])\n",
    "y = df['sentiment']\n",
    "# Transform the training data using the CountVectorizer\n",
    "\n",
    "# Initialize and train the Logistic Regression classifier\n",
    "\n",
    "log_classifier = LinearSVC()\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(log_classifier, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Report the 10-fold cross-validation performance\n",
    "mean_accuracy = np.mean(scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [20 pts] Use only the first 1000 words in Tf-Idf features and compute 10-fold CV classification evaluation performance. We expect a lower score compared to when using the full set of features. Recall that when Tf-Idf features are ranked, the top features exhibit a high information content, since Idf normalizes the document frequencies properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. [20 pts] Add the two columns of positive and negative opinions (e.g., counts) to the 1000 Tf-Idf features in (2.) and re-compute the 10-fold CV classification evaluation. Did opinions from (1.) help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. [20 pts] Compare the ranked features as in the previous homework, indicate where the two added opinion features located with respect to the high-ranked Tf-Idf features (as we conducted in the previous assignments)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [20 pts] We were unable to improve the labeling and/or classification as it looks like the IMDB review dataset ground truth is generated from something else.\n",
    "List some possibilities about the source of the ground truth of original dataset.\n",
    "Now attempt to extract the voting score from the review (if exists), for example the first review has it.\n",
    "Outline an approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
